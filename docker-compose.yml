version: "3.8"

services:
  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    volumes:
      - ./server/Database.sqlite:/app/Database.sqlite # Persist the SQLite database between container restarts
    expose:
      - "3000" # Expose port 3000 to other containers in the same network
    environment:
      - SCRAPER_SECRET=${SCRAPER_SECRET:-your_very_secret_string_here}
      - SEQUELIZE_LOGGING=false
      - ANALYTICS_STORAGE_ITEMS=200
      - ANALYTICS_STORAGE_TIME_MINUTES=10
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 1m30s # Time between health checks
      timeout: 30s # Time to wait for a health check to succeed
      retries: 5 # Number of retries before considering the service unhealthy
      start_period: 15s # Time to wait before starting health checks

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
      args:
        PUBLIC_API_URL: "https://api.bettercinestar.lukaslovretic.from.hr"
    # ports:
    #   - "8080:80" # Map port 8080 on the host to port 80 in the container
    depends_on:
      - server
    restart: unless-stopped

  # Scraper service (runs once and exits)
  scraper:
    build:
      context: ./scraper
      dockerfile: Dockerfile
    environment:
      - SERVER_API_URL=http://server:3000/api/v1/scrape-results
      - SCRAPER_SECRET=${SCRAPER_SECRET:-your_very_secret_string_here}
      # Set RUN_MODE to 'once' to run the scraper once and exit, or 'scheduled' to run on a schedule
      - RUN_MODE=scheduled
      # Set the cron schedule for periodic runs (only used if RUN_MODE=scheduled)
      - CRON_SCHEDULE=0 2 * * * # Every day at 2 AM
    depends_on:
      - server
    restart: unless-stopped
